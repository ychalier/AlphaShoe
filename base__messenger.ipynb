{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaShoe\n",
    "\n",
    "SD210 Challenge\n",
    "\n",
    " - [scoreboard and submissions](http://datachallenge.enst.fr/)\n",
    " - [starting kit](http://nbviewer.jupyter.org/urls/dl.dropboxusercontent.com/s/hmrfrurkyoohi3v/moussab%20djerrab%20-%20DataChallenge_ShoeReturns.ipynb)\n",
    " - [training data](https://www.dropbox.com/sh/uo4oudw43j45mp3/AACA0UqkitNKSWdE_7fs2Wbla?dl=0)\n",
    " - [dictionnary](https://www.dropbox.com/sh/uo4oudw43j45mp3/AACA0UqkitNKSWdE_7fs2Wbla?dl=0&preview=dictionnary.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#deep\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def log(text, t_start=None):\n",
    "    if t_start is None:\n",
    "        print(text)\n",
    "    else:\n",
    "        elapsed_time = round(time.time() - t_start, 2)\n",
    "        print(text + \"\\t(\" + str(elapsed_time) + \"s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files loaded\t(48.54s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "customers = pd.read_csv(\"data/customers.csv\")\n",
    "products = pd.read_csv(\"data/products.csv\")\n",
    "x_train = pd.read_csv(\"data/X_train.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "x_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "log(\"files loaded\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SizeAdviceDescription\n",
    "SizeAdviceDescriptionCleaner = {}\n",
    "SizeAdviceDescriptionCleaner['nan'] = 0\n",
    "SizeAdviceDescriptionCleaner['Ce mod\\xc3\\x83\\xc2\\xa8le chausse normalement'] = 0\n",
    "SizeAdviceDescriptionCleaner['Mod\\xc3\\x83\\xc2\\xa8le confortable, convient aux pieds larges'] = -.5\n",
    "SizeAdviceDescriptionCleaner['Mod\\xc3\\x83\\xc2\\xa8le \\xc3\\x83\\xc2\\xa9troit, convient aux pieds fins'] = .5\n",
    "SizeAdviceDescriptionCleaner['Prenez votre pointure habituelle'] = 0\n",
    "SizeAdviceDescriptionCleaner['Chaussant particuli\\xc3\\x83\\xc2\\xa8rement g\\xc3\\x83\\xc2\\xa9n\\xc3\\x83\\xc2\\xa9reux. Nous vous conseillons de choisir deux tailles en dessous de votre pointure habituelle.'] = -2\n",
    "SizeAdviceDescriptionCleaner['Chaussant petit. Si vous \\xc3\\x83\\xc2\\xaates habituellement entre deux pointures, nous vous conseillons de choisir une demi taille au-dessus de votre pointure habituelle.'] = .5\n",
    "SizeAdviceDescriptionCleaner['Prenez une taille au-dessus de sa pointure !'] = 1\n",
    "SizeAdviceDescriptionCleaner['Prenez une taille au-dessus de votre pointure habituelle'] = 1\n",
    "SizeAdviceDescriptionCleaner['Prenez une taille en dessous de sa pointure !'] = -1\n",
    "SizeAdviceDescriptionCleaner['Prenez une taille en dessous de votre pointure habituelle'] = -1\n",
    "\n",
    "# BirthDate\n",
    "def age(birthdate):\n",
    "    if type(birthdate) == type(\" \"):\n",
    "        return 2016 - int(birthdate[:4])\n",
    "    return None\n",
    "\n",
    "# OrderCreationDate and SeasonLabel\n",
    "def order_season(orderdate):\n",
    "    month = int(orderdate[5:7])\n",
    "    if month >= 4 and month <= 9:\n",
    "        return \"Printemps/Et\\xc3\\x83\\xc2\\xa9\"\n",
    "    return \"Automne/Hiver\"\n",
    "\n",
    "\n",
    "def build_df(x):\n",
    "    \"\"\"Builds a pandas DataFrame with clean columns from a read CSV\"\"\"\n",
    "    \n",
    "    t = time.time()\n",
    "    m = None\n",
    "    \n",
    "    # join\n",
    "    m = pd.merge(x, products, how='left', on='VariantId', suffixes=('_pr', ''))\n",
    "    m = pd.merge(m, customers, how='left', on='CustomerId', suffixes=('_cs', ''))\n",
    "    \n",
    "    # converting UnitPMPEUR\n",
    "    m.UnitPMPEUR = m[\"UnitPMPEUR\"].map(lambda row: float(row.replace(',', '.')))\n",
    "    \n",
    "    # building news columns\n",
    "    m[\"MatchGender\"] = m[\"Gender\"] == m[\"GenderLabel\"]\n",
    "    m[\"MatchSeason\"] = m[\"SeasonLabel_pr\"] == m[\"SeasonLabel\"]\n",
    "    m[\"OrderSeason\"] = m[\"OrderCreationDate\"].map(order_season)\n",
    "    m[\"MatchOrderSeason\"] = m[\"OrderSeason\"] == m[\"SeasonLabel\"]\n",
    "    \n",
    "    # cleaning\n",
    "    m[\"SizeAdviceDescription\"] = m[\"SizeAdviceDescription\"].map(SizeAdviceDescriptionCleaner)\n",
    "    m[\"BirthDate\"] = m[\"BirthDate\"].map(age)\n",
    "        \n",
    "    # removing useless columns\n",
    "    blacklist = ['VariantId', 'CustomerId', 'OrderNumber', 'LineItem',\n",
    "                 'ProductColorId', 'BrandId', 'SupplierColor', 'OrderShipDate',\n",
    "                 'ProductId', 'BillingPostalCode', 'FirstOrderDate',\n",
    "                 'OrderStatusLabel', 'MinSize', 'MaxSize', 'OrderSeason',\n",
    "                 'OrderCreationDate', 'SubtypeLabel', 'ProductType'\n",
    "                ]\n",
    "    whitelist = None\n",
    "    if blacklist is not None:\n",
    "        m = m.drop(blacklist, axis=1)\n",
    "    if whitelist is not None:\n",
    "        for col in m.columns:\n",
    "            if col not in whitelist:\n",
    "                m = m.drop([col], axis=1)\n",
    "\n",
    "    print \"dataframe shape:\", m.shape\n",
    "    log(\"dataframe built\", t)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returns_frequency(x, y, col, step):\n",
    "    \"\"\"Returns the returns frequencies for each value of a column\"\"\"\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    # counting occurences of each column value\n",
    "    occurrences = {}\n",
    "    for i, o in x.loc[::step].iterrows():\n",
    "        counter += 1\n",
    "        if str(o[col]) not in occurrences.keys():\n",
    "            occurrences[str(o[col])] = [0., 0.]\n",
    "        if y.loc[i, [\"ReturnQuantityBin\"]][0] == 0.0:\n",
    "            occurrences[str(o[col])][0] += 1.\n",
    "        else:\n",
    "            occurrences[str(o[col])][1] += 1.\n",
    "    \n",
    "    # computing the returns frequency, stored in `recap`\n",
    "    recap, values = [], []\n",
    "    for val, (zeros, ones) in occurrences.items():\n",
    "        values.append(((ones / (zeros + ones))))\n",
    "        recap.append((val, values[-1]))\n",
    "    recap.sort(key=lambda row: row[0])\n",
    "    \n",
    "    # computing variance and relative variance\n",
    "    var = np.var(values)\n",
    "    rel = var / len(values)\n",
    "    \n",
    "    return recap, var, rel, counter\n",
    "\n",
    "\n",
    "def column_stats(x, y, col, step, verbose):\n",
    "    \"\"\"Computes the statistics for one column\"\"\"\n",
    "    \n",
    "    print \"\\n----- \" + col + \" -----\"\n",
    "    recap, var, rel, counter = returns_frequency(x, y, col, step)\n",
    "    \n",
    "    if verbose:\n",
    "        for (val, freq) in recap:\n",
    "            print val, \"\\t\", freq, \"returns\"\n",
    "\n",
    "    print \"variance:\", round(var, 5), \"\\tvalues count:\", len(recap)\n",
    "    return recap, var, rel, counter\n",
    "\n",
    "\n",
    "def compute_statistics(x, y, blacklist=[], whitelist=[], step=100, verbose=False):\n",
    "    ignored = []\n",
    "    labels_g, labels_n = [], []\n",
    "    scattering_g, scattering_n = [], []      # variances\n",
    "    r_scattering_g, r_scattering_n = [], []  # variance divided by the number of differents values\n",
    "    \n",
    "    counter_cols = 0\n",
    "    counter_rows = 0\n",
    "    \n",
    "    for col in x.columns:\n",
    "        if col not in blacklist and x[col].dtype in [\"object\", \"bool\"]:\n",
    "            counter_cols += 1\n",
    "            labels_g.append(col)\n",
    "            recap, var, rel, counter_rows = column_stats(x, y, col, step, verbose)\n",
    "            scattering_g.append(var)\n",
    "            r_scattering_g.append(rel)\n",
    "        elif col not in blacklist and x[col].dtype in [\"float64\", \"int64\"]:\n",
    "            counter_cols += 1\n",
    "            labels_n.append(col)\n",
    "            recap, var, rel, counter_rows = column_stats(x, y, col, step, verbose)\n",
    "            scattering_n.append(var)\n",
    "            r_scattering_n.append(rel)\n",
    "            if col in whitelist:\n",
    "                plot_dots([float(v[0]) for v in recap], [v[1] for v in recap], col)\n",
    "        else:\n",
    "            ignored.append(col)\n",
    "    \n",
    "    print \"\\n\\nanalyzed\", counter_cols, \"columns and\", counter_rows, \"rows\"\n",
    "    print \"\\nignored columns:\", ignored\n",
    "    plot_barchart(labels_g, scattering_g, r_scattering_g, \"general columns\")\n",
    "    plot_barchart(labels_g, scattering_g, r_scattering_g, \"numerical columns\")\n",
    "    \n",
    "\n",
    "def plot_barchart(labels, values_l, values_r, title):\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    ind = np.arange(len(values_l))\n",
    "    width = .35\n",
    "    ax.bar(ind - width/2, values_l, width)\n",
    "    ax.bar(ind + width/2, values_r, width)\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(labels)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_dots(xs, ys, xlabel):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"returns frequency\")\n",
    "    plt.plot(xs, ys, 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (1067290, 34)\n",
      "dataframe built\t(13.09s)\n"
     ]
    }
   ],
   "source": [
    "df_stats = build_df(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_statistics(df_stats, y_train, blacklist=[], whitelist=df_stats.columns, step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TO REMOVE\n",
    "def prune(x, columns, variability, threshold):\n",
    "    to_remove = []\n",
    "    for i, col in enumerate(columns):\n",
    "        if variability[i] < threshold:\n",
    "            to_remove.append(col)\n",
    "    return x.drop(to_remove, axis=1)\n",
    "\n",
    "df_train_pruned = prune(df_train, labels, variability, 0.001)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask(m):\n",
    "    columns2bin = [col for col in m.columns if m[col].dtype == 'object']\n",
    "    other_cols = m.drop(columns2bin, axis=1)\n",
    "    new_cols = pd.get_dummies(m.loc[:, columns2bin])\n",
    "    res = pd.concat([other_cols, new_cols], axis=1)\n",
    "    res = res.fillna(0)\n",
    "    print \"new shape:\", res.shape\n",
    "    return res\n",
    "\n",
    "def compute(name, clf, x1, x2, slc=100000):\n",
    "    print \"\\n-----\", name, \"-----\"\n",
    "    clf.fit(x1.iloc[:slc], y_train.ReturnQuantityBin[:slc])\n",
    "    \n",
    "    predict_train = clf.predict_proba(x1.iloc[:slc])\n",
    "    score_train = roc_auc_score(y_train.ReturnQuantityBin[:slc], predict_train[:, 1])\n",
    "    print \"train score:\", score_train\n",
    "    \n",
    "    predict_test = clf.predict_proba(x1.iloc[slc:2 * slc])\n",
    "    score_test = roc_auc_score(y_train.ReturnQuantityBin[slc:2 * slc], predict_test[:, 1])\n",
    "    print \"test score:\", score_test\n",
    "    return score_train, score_test\n",
    "\n",
    "def compute_all(x1, x2, slc=100000):\n",
    "    \"\"\"Tries different classifiers and returns the best one (best test score)\"\"\"\n",
    "    t = time.time()\n",
    "    best_index, best_score = None, None\n",
    "    \n",
    "    print \"train shape:\\t\", x1.shape, \"\\t\", y_train.shape\n",
    "    print \"test shape:\\t\", x2.shape, \"\\t\", y_test.shape\n",
    "    \n",
    "    classifiers = [(\"random forest\", RandomForestClassifier()),\n",
    "                   (\"decision tree\", DecisionTreeClassifier()),\n",
    "                   (\"logistic regression\", LogisticRegression()),\n",
    "                    (\"DEEP\",MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 10), random_state=1))]\n",
    "    \n",
    "    for i, (name, clf) in enumerate(classifiers):\n",
    "        score_train, score_test = compute(name, clf, x1, x2, slc)\n",
    "        if best_score is None or score_test > best_score:\n",
    "            best_index, best_score = i, score_test\n",
    "    \n",
    "    log(\"\\nbest classifier: \" + classifiers[best_index][0], t)\n",
    "    return classifiers[best_index][1]\n",
    "\n",
    "def output(clf, x1, x2):\n",
    "    t = time.time()\n",
    "    y_tosubmit = clf.predict_proba(x2.loc[:, x1.columns].fillna(0))\n",
    "    \n",
    "    timestamp = '{0:%Y_%m_%d_%H_%M_%S}'.format(datetime.datetime.now())\n",
    "    filename = \"ypred_{0}.txt\".format(timestamp)\n",
    "    np.savetxt(filename, y_tosubmit[:,1], fmt='%f')\n",
    "    \n",
    "    f = open(\"predictions.txt\", 'a')\n",
    "    f.write(timestamp + '\\n' + repr(clf).replace('\\n          ', '') + '\\n\\n')\n",
    "    f.close()\n",
    "    \n",
    "    print \"shape:\", y_tosubmit.shape\n",
    "    log(\"generated output at \" + filename, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Computation test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (800468, 34)\n",
      "dataframe built\t(10.21s)\n"
     ]
    }
   ],
   "source": [
    "df_test = build_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (1067290, 34)\n",
      "dataframe built\t(12.95s)\n"
     ]
    }
   ],
   "source": [
    "df_train = build_df(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape: (1067290, 158)\n",
      "new shape: (800468, 166)\n",
      "applied mask\t(7.8s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "x1 = mask(df_train)\n",
    "x2 = mask(df_test)\n",
    "log(\"applied mask\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:\t(1067290, 158) \t(1067290, 4)\n",
      "test shape:\t(800468, 166) \t(800468, 4)\n",
      "\n",
      "----- random forest -----\n",
      "train score: 0.994864576917\n",
      "test score: 0.570640507496\n",
      "\n",
      "----- decision tree -----\n",
      "train score: 0.999397896888\n",
      "test score: 0.533917674453\n",
      "\n",
      "----- logistic regression -----\n",
      "train score: 0.639062743106\n",
      "test score: 0.632971765689\n",
      "\n",
      "----- DEEP -----\n",
      "train score: 0.651498651424\n",
      "test score: 0.6356969107\n",
      "\n",
      "best classifier: DEEP\t(118.65s)\n"
     ]
    }
   ],
   "source": [
    "clf = compute_all(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisamat/venv/lib/python2.7/site-packages/ipykernel_launcher.py:47: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/Users/francoisamat/venv/lib/python2.7/site-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (800468, 2)\n",
      "generated output at ypred_2018_04_15_22_43_37.txt\t(19.02s)\n"
     ]
    }
   ],
   "source": [
    "output(clf, x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)\n",
    "\n",
    "Best scores reached with `n_components` at 96:\n",
    " - train score: 0.6388630967451936\n",
    " - test score:  0.6331956289779485\n",
    "\n",
    "Above, scores are deacreasing.\n",
    "\n",
    "**Note:** the result from `.transform()` is a Numpy array. Therefore the slicing is different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def try_pca(data, n_components):\n",
    "    print \"\\n----- PCA\", n_components, \"-----\"\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(data)\n",
    "    x = pca.transform(data)\n",
    "    clf = LogisticRegression()\n",
    "    slc = 100000\n",
    "    clf.fit(x[:slc, :], y_train.ReturnQuantityBin[:slc])\n",
    "    \n",
    "    predict_train = clf.predict_proba(x[:slc, :])\n",
    "    score_train = roc_auc_score(y_train.ReturnQuantityBin[:slc], predict_train[:, 1])\n",
    "    print \"train score:\", score_train\n",
    "    \n",
    "    predict_test = clf.predict_proba(x[slc:2 * slc, :])\n",
    "    score_test = roc_auc_score(y_train.ReturnQuantityBin[slc:2 * slc], predict_test[:, 1])\n",
    "    print \"test score:\", score_test\n",
    "    \n",
    "    return score_train, score_test, pca\n",
    "\n",
    "for n in range(1, 100, 5):\n",
    "    try_pca(x1, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation prediction\n",
    "\n",
    "This is an _attempt_, scores did not met expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def cross_val(name, clf, slc=100000):\n",
    "    print \"\\n-----\", name, \"-----\"\n",
    "    predict_train = cross_val_predict(clf, x1.iloc[:slc], y_train.ReturnQuantityBin[:slc], cv=10, method='predict_proba')\n",
    "    score_train = roc_auc_score(y_train.ReturnQuantityBin[:slc], predict_train[:, 1])\n",
    "    print \"train score:\", score_train\n",
    "    return score_train\n",
    "\n",
    "cross_val(\"LogisticRegression\", LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(x, y, steps=10, slc=100000, plot=True):\n",
    "    scores_train, scores_test = [], []\n",
    "    best_clf, best_score = None, None\n",
    "    \n",
    "    z = x.copy(deep=True)\n",
    "    z[\"ReturnQuantityBin\"] = y.ReturnQuantityBin\n",
    "    \n",
    "    for k in range(steps):\n",
    "        u = z.sample(frac=1)\n",
    "        v = u.loc[:, [\"ReturnQuantityBin\"]]\n",
    "        u = u.drop([\"ReturnQuantityBin\"], axis=1)\n",
    "        \n",
    "        #clf = LogisticRegression()\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 10), random_state=1)\n",
    "        clf.fit(u.iloc[:slc], v.ReturnQuantityBin[:slc])\n",
    "        \n",
    "        predict_train = clf.predict_proba(u.iloc[:slc])\n",
    "        score_train = roc_auc_score(v.ReturnQuantityBin[:slc], predict_train[:, 1])\n",
    "    \n",
    "        predict_test = clf.predict_proba(u.iloc[slc:2 * slc])\n",
    "        score_test = roc_auc_score(v.ReturnQuantityBin[slc:2 * slc], predict_test[:, 1])\n",
    "        \n",
    "        if best_clf is None or score_test > best_score:\n",
    "            best_clf, best_score = clf, score_test\n",
    "        \n",
    "        if plot:\n",
    "            print \"test\", k, \"\\ttrain:\", score_train, \"\\ttest:\", score_test\n",
    "        \n",
    "        scores_train.append(score_train)\n",
    "        scores_test.append(score_test)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.xlabel(\"train score\")\n",
    "        plt.ylabel(\"test score\")\n",
    "        plt.plot(scores_train, scores_test, '+')\n",
    "        plt.show()\n",
    "    \n",
    "    return scores_train, scores_test, best_clf, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-035cd28fc9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clf' is not defined"
     ]
    }
   ],
   "source": [
    "output(best_clf, x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice 10000 \t0.658323403452\n",
      "slice 20000 \t0.659244885548\n",
      "slice 30000 \t0.658527744854\n",
      "slice 40000 \t0.659320759677\n",
      "slice 50000 \t0.661305405909\n",
      "slice 60000 \t0.662496890081\n",
      "slice 70000 \t0.659767449335\n",
      "slice 80000 \t0.659044412524\n",
      "slice 90000 \t0.66011393161\n",
      "slice 100000 \t0.658210195611\n",
      "slice 110000 \t0.658148778931\n"
     ]
    }
   ],
   "source": [
    "def try_slice(plot=True, steps=10):\n",
    "\n",
    "    slices, scores, classifiers = [], [], {}\n",
    "    best_slice, best_score = None, None\n",
    "\n",
    "    for slc in range(10000, 200001, 10000):\n",
    "        sc_train, sc_test, clf, score = shuffle(x1, y_train, slc=slc, steps=steps, plot=False)\n",
    "        slices.append(slc)\n",
    "        scores.append(score)\n",
    "        if best_slice is None or best_score < score:\n",
    "            best_slice, best_score = slc, score\n",
    "        classifiers[slc] = clf\n",
    "        print \"slice\", slc, \"\\t\", score\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.xlabel(\"slice\")\n",
    "        plt.ylabel(\"score\")\n",
    "        plt.plot(slices, scores, '-o')\n",
    "        plt.show()\n",
    "    \n",
    "    return classifiers[best_slice]\n",
    "\n",
    "best_clf = try_slice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some interpretation__\n",
    "\n",
    "Tests showed that the slice does not really impact the score. However, the more data are processed the more stabilized reults get. One then may select let's say `50000` as a default slice and then perform much more tests to try to, by chance, find a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_train, sc_test, clf, score = shuffle(x1, y_train, slc=50000, steps=10, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisamat/venv/lib/python2.7/site-packages/ipykernel_launcher.py:47: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (800468, 2)\n",
      "generated output at ypred_2018_04_16_03_41_32.txt\t(22.94s)\n"
     ]
    }
   ],
   "source": [
    "output(clf, x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for max_depth in range(1, 201, 5):\n",
    "    clf = RandomForestClassifier(max_depth=max_depth)\n",
    "    score = cross_val_score(clf, x1, y_train, cv=10)\n",
    "    print score =\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    ">>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    ">>> scores                                              \n",
    "array([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
